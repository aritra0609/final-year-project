ğŸ§  Generative AI Chatbot with RAG
A blazing-fast, real-time AI chatbot powered by Groq, OpenAI/Mistral, LangChain, and Tavily, with a modern FastAPI + Streamlit stack.

ğŸš€ Features
ğŸ” RAG pipeline with optional live web search (Tavily)

âš¡ Ultra-fast inference via Groq for near-instant responses

ğŸ§  Reasoning & tool orchestration using LangGraph ReAct Agent

ğŸŒ Full-stack: Streamlit frontend + FastAPI backend

âœ… Validated input with Pydantic, clean env with pipenv

ğŸ› ï¸ Tech Stack
LLMs: OpenAI / Mistral
Inference: Groq
Tools: Tavily API
Memory & Agents: LangChain + LangGraph
UI: Streamlit
API: FastAPI + Uvicorn
Validation: Pydantic
Env Mgmt: pipenv

ğŸ“Œ How It Works
User sends a query via Streamlit (with optional web search).

FastAPI routes it to an AI agent (LangGraph ReAct).

If allowed, Tavily fetches live data; Groq accelerates the LLM.

Final answer is returned to the UI.

ğŸ“ˆ Example

POST /chat
{
  "query": "Latest update on GPT-4.5?",
  "allow_search": true
}
